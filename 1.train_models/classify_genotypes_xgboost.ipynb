{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "quD0wavRs0"
   },
   "source": [
    "# Classify WT and Null Genotypes Logistic Regression\n",
    "Plates 3, 3p, and 5 are used in all splits to classify genotypes either (WT or Null)\n",
    "The feature selected data is used in all data splits.\n",
    "Pre-evaluation metrics are stored from all splits and these plates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T20:21:08.300458Z",
     "iopub.status.busy": "2024-07-19T20:21:08.300354Z",
     "iopub.status.idle": "2024-07-19T20:21:08.745708Z",
     "shell.execute_reply": "2024-07-19T20:21:08.745264Z"
    },
    "jukit_cell_id": "RcnXoNLyM2"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06T17:44:31 [train_12_08_07_53_xgboost_train] INFO: Initialized logger.\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = \"xgboost\"\n",
    "ROLE = \"train\"\n",
    "\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import pathlib\n",
    "\n",
    "# ============================================\n",
    "# 1) Choose a RUN_ID\n",
    "# ============================================\n",
    "RUN_ID = datetime.now().strftime(\"%m_%d_%H_%M\")\n",
    "\n",
    "RUN_ID = \"12_08_16_45\"\n",
    "\n",
    "RUN_ID = \"12_08_07_53\"\n",
    "ANALYSIS_TYPE = \"train\"\n",
    "\n",
    "\n",
    "def setup_logger(\n",
    "    run_id: str,\n",
    "    model_id: str,\n",
    "    role: str,\n",
    "    log_dir: str = \"logs\",\n",
    "    analysis_type: str = ANALYSIS_TYPE,\n",
    ") -> logging.Logger:\n",
    "    \"\"\"\n",
    "    Create a logger that writes to both stdout and a log file.\n",
    "\n",
    "    - Logger name:  \"<analysis_type>_<run_id>_<model_id>_<role>\"\n",
    "    - Log file:     \"log_<analysis_type>_<run_id>_<model_id>.log\" in `log_dir`\n",
    "      (shared by all notebooks for the same model & run & analysis_type).\n",
    "    \"\"\"\n",
    "    log_path = pathlib.Path(log_dir)\n",
    "    log_path.mkdir(exist_ok=True)\n",
    "\n",
    "    logger_name = f\"{analysis_type}_{run_id}_{model_id}_{role}\"\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.propagate = False  # don't duplicate logs to root logger\n",
    "\n",
    "    # Avoid adding handlers multiple times if the cell is re-run\n",
    "    if not logger.handlers:\n",
    "        # Common formatter for both handlers\n",
    "        formatter = logging.Formatter(\n",
    "            fmt=\"%(asctime)s [%(name)s] %(levelname)s: %(message)s\",\n",
    "            datefmt=\"%Y-%m-%dT%H:%M:%S\",\n",
    "        )\n",
    "\n",
    "        # Stream handler (stdout)\n",
    "        stream_handler = logging.StreamHandler()\n",
    "        stream_handler.setLevel(logging.INFO)\n",
    "        stream_handler.setFormatter(formatter)\n",
    "        logger.addHandler(stream_handler)\n",
    "\n",
    "        # File handler (one file per analysis_type + run_id + model_id)\n",
    "        log_file = log_path / f\"log_{analysis_type}_{run_id}_{model_id}.log\"\n",
    "        file_handler = logging.FileHandler(log_file)\n",
    "        file_handler.setLevel(logging.INFO)\n",
    "        file_handler.setFormatter(formatter)\n",
    "        logger.addHandler(file_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "\n",
    "logger = setup_logger(RUN_ID, MODEL_ID, ROLE)\n",
    "logger.info(\"Initialized logger.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "tdSJIClZGb"
   },
   "source": [
    "## Find the root of the git repo on the host system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T20:21:08.747608Z",
     "iopub.status.busy": "2024-07-19T20:21:08.747418Z",
     "iopub.status.idle": "2024-07-19T20:21:08.750332Z",
     "shell.execute_reply": "2024-07-19T20:21:08.750003Z"
    },
    "jukit_cell_id": "QmTyYX7yVG"
   },
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "cwd = pathlib.Path.cwd()\n",
    "\n",
    "if (cwd / \".git\").is_dir():\n",
    "    root_dir = cwd\n",
    "\n",
    "else:\n",
    "    root_dir = None\n",
    "    for parent in cwd.parents:\n",
    "        if (parent / \".git\").is_dir():\n",
    "            root_dir = parent\n",
    "            break\n",
    "\n",
    "# Check if a Git root directory was found\n",
    "if root_dir is None:\n",
    "    raise FileNotFoundError(\"No Git root directory found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "eSQXraMRCI"
   },
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "cZx8xNCyZq"
   },
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T20:21:08.751806Z",
     "iopub.status.busy": "2024-07-19T20:21:08.751585Z",
     "iopub.status.idle": "2024-07-19T20:21:09.067096Z",
     "shell.execute_reply": "2024-07-19T20:21:09.066546Z"
    },
    "jukit_cell_id": "xdgUvt0md2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06T17:44:32 [train_12_08_07_53_xgboost_train] INFO: Number of single-cells total per plate:\n",
      "2025-12-06T17:44:32 [train_12_08_07_53_xgboost_train] INFO: Plate 3: 10206\n",
      "2025-12-06T17:44:32 [train_12_08_07_53_xgboost_train] INFO: Plate 3 prime: 5126\n",
      "2025-12-06T17:44:32 [train_12_08_07_53_xgboost_train] INFO: Plate 5: 5348\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: If the data (within the cell painting directory) is stored in a different location, add location here\n",
    "repo_dir = pathlib.Path(\n",
    "    \"/Users/marktalbot/Documents/VC Studio Homework Folders/HighRisk/nf1_schwann_cell_painting_data\"\n",
    ")\n",
    "\n",
    "# Set data level\n",
    "data_level = \"cleaned\"\n",
    "\n",
    "# Main directory path (converted or cleaned data)\n",
    "if data_level == \"cleaned\":\n",
    "    data_dir = pathlib.Path(\n",
    "        repo_dir / \"3.processing_features/data/single_cell_profiles/cleaned_sc_profiles\"\n",
    "    )\n",
    "else:\n",
    "    data_dir = pathlib.Path(\n",
    "        repo_dir / \"3.processing_features/data/single_cell_profiles\"\n",
    "    )\n",
    "\n",
    "plate3df_path = pathlib.Path(data_dir / \"Plate_3_sc_feature_selected.parquet\").resolve(\n",
    "    strict=True\n",
    ")\n",
    "plate3pdf_path = pathlib.Path(\n",
    "    data_dir / \"Plate_3_prime_sc_feature_selected.parquet\"\n",
    ").resolve(strict=True)\n",
    "plate5df_path = pathlib.Path(data_dir / \"Plate_5_sc_feature_selected.parquet\").resolve(\n",
    "    strict=True\n",
    ")\n",
    "\n",
    "plate3df = pd.read_parquet(plate3df_path)\n",
    "plate3pdf = pd.read_parquet(plate3pdf_path)\n",
    "plate5df = pd.read_parquet(plate5df_path)\n",
    "\n",
    "logger.info(\"Number of single-cells total per plate:\")\n",
    "logger.info(f\"Plate 3: {plate3df.shape[0]}\")\n",
    "logger.info(f\"Plate 3 prime: {plate3pdf.shape[0]}\")\n",
    "logger.info(f\"Plate 5: {plate5df.shape[0]}\")\n",
    "\n",
    "# Set the seed\n",
    "rng = np.random.default_rng(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "G0IEMyaFva"
   },
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T20:21:09.069370Z",
     "iopub.status.busy": "2024-07-19T20:21:09.069143Z",
     "iopub.status.idle": "2024-07-19T20:21:09.071752Z",
     "shell.execute_reply": "2024-07-19T20:21:09.071419Z"
    },
    "jukit_cell_id": "byqT0qeQSc"
   },
   "outputs": [],
   "source": [
    "data_path = pathlib.Path(\"data_xgboost\")\n",
    "data_path.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "YtBIYKchGc"
   },
   "source": [
    "## Splitting and Processing\n",
    "Functions to split and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T20:21:09.073333Z",
     "iopub.status.busy": "2024-07-19T20:21:09.073098Z",
     "iopub.status.idle": "2024-07-19T20:21:09.077658Z",
     "shell.execute_reply": "2024-07-19T20:21:09.077314Z"
    },
    "jukit_cell_id": "qP1KgMqkE7"
   },
   "outputs": [],
   "source": [
    "gene_column = \"Metadata_genotype\"\n",
    "\n",
    "\n",
    "def down_sample_by_genotype(_df):\n",
    "    \"\"\"\n",
    "    Return an equal number of cells from each genotype.\n",
    "    The number of cells in a genotype is the minimum number of cells from all genotypes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    _df: Pandas DataFrame\n",
    "        The data to be downsampled by the gene_column column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The DataFrame downsampled by genotype.\n",
    "    \"\"\"\n",
    "    min_gene = _df[gene_column].value_counts().min()\n",
    "    return _df.groupby(gene_column, group_keys=False).apply(\n",
    "        lambda x: x.sample(n=min_gene, random_state=0)\n",
    "    )\n",
    "\n",
    "\n",
    "def process_plates(_df):\n",
    "    \"\"\"\n",
    "    Drop rows with NaNs from the single cell data and remove HET cells.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    _df: Pandas DataFrame\n",
    "        Uncleaned plate data with NaNs and HET cells to be removed. Contains the column \"Metadata_genotype\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    _df: Pandas DataFrame\n",
    "        Cleaned single cell data by removing NaNs and HET cells.\n",
    "    \"\"\"\n",
    "    _df.dropna(inplace=True)\n",
    "    _df = _df.loc[_df[gene_column] != \"HET\"]\n",
    "    return _df\n",
    "\n",
    "\n",
    "def shuffle_data(_X):\n",
    "    \"\"\"\n",
    "    Shuffle the columns of the input DataFrame independently.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    _X: Pandas DataFrame\n",
    "        Input feature data for shuffling the columns.\n",
    "    \"\"\"\n",
    "    for column in _X.columns:\n",
    "        _X[column] = rng.permutation(_X[column])\n",
    "\n",
    "\n",
    "def store_pre_evaluation_data(_X, _y, _metadata, _datasplit):\n",
    "    \"\"\"\n",
    "    Store model data to evaluate performance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    _X: Pandas DataFrame\n",
    "        Feature DataFrame from a given plate and data split.\n",
    "    _y: numpy.ndarray\n",
    "        A numerically encoded label vector ordered according to _X.\n",
    "    _metadata: Pandas DataFrame\n",
    "        Metadata (one row per sample) to carry through.\n",
    "    _datasplit: str\n",
    "        Name of the datasplit (for example, \"train\", \"val\", \"test\", \"shuffled_*\").\n",
    "    \"\"\"\n",
    "    # \"model\" is the currently trained classifier (either CV fold or final model)\n",
    "    eval_data[f\"probability_{probability_class}\"].extend(\n",
    "        model.predict_proba(_X)[:, 1].tolist()\n",
    "    )\n",
    "    eval_data[\"datasplit\"].extend([_datasplit] * _X.shape[0])\n",
    "    eval_data[\"predicted_genotype\"].extend(model.predict(_X).tolist())\n",
    "    eval_data[\"true_genotype\"].extend(_y.tolist())\n",
    "    for meta_col in _metadata.columns:\n",
    "        eval_data[meta_col].extend(_metadata[meta_col].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "R7X8nR4SsB"
   },
   "source": [
    "## Split and process plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T20:21:09.079175Z",
     "iopub.status.busy": "2024-07-19T20:21:09.078970Z",
     "iopub.status.idle": "2024-07-19T20:21:09.081229Z",
     "shell.execute_reply": "2024-07-19T20:21:09.080896Z"
    },
    "jukit_cell_id": "z9zzUXpQ67"
   },
   "outputs": [],
   "source": [
    "def create_splits(_wells, _plate):\n",
    "    \"\"\"\n",
    "    Create data splits for model training. The splits are rest (train and validation) and test.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    _wells: List(String)\n",
    "        The well names from which single cells will be used in the test set.\n",
    "\n",
    "    _plate: Pandas Dataframe\n",
    "        Single cell data from one of the plate's containing a \"Metadata_Well\" column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dataframes of the split single cell data.\n",
    "    \"\"\"\n",
    "\n",
    "    return (\n",
    "        _plate[~_plate[\"Metadata_Well\"].isin(_wells)],\n",
    "        _plate[_plate[\"Metadata_Well\"].isin(_wells)],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T20:21:09.082677Z",
     "iopub.status.busy": "2024-07-19T20:21:09.082489Z",
     "iopub.status.idle": "2024-07-19T20:21:09.372731Z",
     "shell.execute_reply": "2024-07-19T20:21:09.372244Z"
    },
    "jukit_cell_id": "qrteU1j4F9"
   },
   "outputs": [],
   "source": [
    "plate3df = process_plates(plate3df)\n",
    "p3_wells = [\"C11\", \"E11\", \"C3\", \"F3\"]\n",
    "rest3df, test3df = create_splits(p3_wells, plate3df)\n",
    "rest3df, test3df = down_sample_by_genotype(rest3df), down_sample_by_genotype(test3df)\n",
    "\n",
    "plate3pdf = process_plates(plate3pdf)\n",
    "p3p_wells = [\"F11\", \"G11\", \"C3\", \"F3\"]\n",
    "rest3pdf, test3pdf = create_splits(p3p_wells, plate3pdf)\n",
    "rest3pdf, test3pdf = down_sample_by_genotype(rest3pdf), down_sample_by_genotype(\n",
    "    test3pdf\n",
    ")\n",
    "\n",
    "plate5df = process_plates(plate5df)\n",
    "p5_wells = [\"C9\", \"E11\", \"E3\", \"G3\"]\n",
    "rest5df, test5df = create_splits(p5_wells, plate5df)\n",
    "rest5df, test5df = down_sample_by_genotype(rest5df), down_sample_by_genotype(test5df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "pnZI3c8SRh"
   },
   "source": [
    "## Combine plate columns across each data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T20:21:09.374908Z",
     "iopub.status.busy": "2024-07-19T20:21:09.374782Z",
     "iopub.status.idle": "2024-07-19T20:21:09.537487Z",
     "shell.execute_reply": "2024-07-19T20:21:09.536874Z"
    },
    "jukit_cell_id": "JPOu8mYg6w"
   },
   "outputs": [],
   "source": [
    "# Columns common to all plates\n",
    "plate_cols = list(\n",
    "    set(plate5df.columns) & set(plate3df.columns) & set(plate3pdf.columns)\n",
    ")\n",
    "\n",
    "restdf = pd.concat(\n",
    "    [rest3df[plate_cols], rest3pdf[plate_cols], rest5df[plate_cols]], ignore_index=True\n",
    ").reset_index(drop=True)\n",
    "\n",
    "testdf = pd.concat(\n",
    "    [test3df[plate_cols], test3pdf[plate_cols], test5df[plate_cols]], ignore_index=True\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "7ckV1bxaO2"
   },
   "source": [
    "## Encode genotypes and extract feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T20:21:09.539765Z",
     "iopub.status.busy": "2024-07-19T20:21:09.539606Z",
     "iopub.status.idle": "2024-07-19T20:21:09.543873Z",
     "shell.execute_reply": "2024-07-19T20:21:09.543515Z"
    },
    "jukit_cell_id": "NTCaf4xXY1"
   },
   "outputs": [],
   "source": [
    "meta_cols = testdf.filter(like=\"Metadata\").columns\n",
    "feat_cols = testdf.drop(columns=meta_cols).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T20:21:09.545393Z",
     "iopub.status.busy": "2024-07-19T20:21:09.545209Z",
     "iopub.status.idle": "2024-07-19T20:21:09.566594Z",
     "shell.execute_reply": "2024-07-19T20:21:09.566165Z"
    },
    "jukit_cell_id": "m7apYZPkME"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "y = le.fit_transform(restdf[\"Metadata_genotype\"])\n",
    "X = restdf.drop(columns=meta_cols)\n",
    "\n",
    "y_test = le.fit_transform(testdf[\"Metadata_genotype\"])\n",
    "X_test = testdf.drop(columns=meta_cols)\n",
    "\n",
    "# Class for saving probabilities\n",
    "probability_class = le.inverse_transform([1])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "RN1oKgi6ph"
   },
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "U6eyLl0ZPH"
   },
   "source": [
    "## Specify parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T20:21:09.568474Z",
     "iopub.status.busy": "2024-07-19T20:21:09.568257Z",
     "iopub.status.idle": "2024-07-19T20:21:09.571406Z",
     "shell.execute_reply": "2024-07-19T20:21:09.571078Z"
    },
    "jukit_cell_id": "sZFW0vn0zv"
   },
   "outputs": [],
   "source": [
    "# Base XGBoost parameters (not searched)\n",
    "xgb_params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"n_jobs\": -1,\n",
    "    \"random_state\": 0,\n",
    "    \"tree_method\": \"hist\",\n",
    "    # (optional) mild default regularization; can be overridden by trial params\n",
    "    # \"lambda\": 1.0,\n",
    "    # \"alpha\": 0.0,\n",
    "}\n",
    "\n",
    "# Discrete search space for XGBoost hyperparameters\n",
    "# CHANGED: bias toward shallower, more regularized models\n",
    "param_choices = {\n",
    "    # slightly higher floor, smaller top-end to keep runtime reasonable\n",
    "    \"n_estimators\": [400, 600, 800],        # was [300, 600, 900]\n",
    "\n",
    "    # shallower trees → less memorization\n",
    "    \"max_depth\": [3, 4],                    # dropped 5\n",
    "\n",
    "    # smaller learning rate → smoother boosting\n",
    "    \"learning_rate\": [0.03, 0.05],          # was [0.05, 0.1]\n",
    "\n",
    "    # always some subsampling → acts as regularization\n",
    "    \"subsample\": [0.7, 0.85],               # dropped 1.0\n",
    "\n",
    "    # feature subsampling as regularization\n",
    "    \"colsample_bytree\": [0.7, 0.85],        # dropped 1.0\n",
    "\n",
    "    # larger min_child_weight → avoids very tiny leaves\n",
    "    \"min_child_weight\": [3, 5],             # dropped 1\n",
    "\n",
    "    # small amount of minimum loss reduction to split\n",
    "    \"gamma\": [0.1, 0.3],                    # dropped 0.0\n",
    "\n",
    "    # NEW: explicit L2/L1 regularization\n",
    "    \"lambda\": [1.0, 3.0, 5.0],              # L2\n",
    "    \"alpha\": [0.0, 0.5, 1.0],               # L1\n",
    "}\n",
    "\n",
    "# Target *total* number of hyperparameter combinations / trials\n",
    "rand_iter = 30\n",
    "\n",
    "# Number of CV folds\n",
    "n_splits = 5\n",
    "\n",
    "# Track best performance (now mean CV AUC; name kept for compatibility)\n",
    "best_acc = -np.inf\n",
    "best_hp = None\n",
    "best_eval_data = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "uBQzEOgaBh"
   },
   "source": [
    "## Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T20:21:09.572973Z",
     "iopub.status.busy": "2024-07-19T20:21:09.572786Z",
     "iopub.status.idle": "2024-07-20T03:13:23.267614Z",
     "shell.execute_reply": "2024-07-20T03:13:23.267154Z"
    },
    "jukit_cell_id": "rHYvmbnZNf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-06 17:44:34,270] Using an existing study with name 'xgb_cv' instead of creating a new one.\n",
      "2025-12-06T17:44:34 [train_12_08_07_53_xgboost_train] INFO: 2025-12-06T17:44:34 [INFO] Loaded Optuna study 'xgb_cv' with 4 total trials (3 completed). Target total trials = 20. Running 17 new trials in this session.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "CategoricalDistribution does not support dynamic value space.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 50\u001b[0m\n\u001b[1;32m     46\u001b[0m trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mask()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Draw hyperparameters from your (more regularized) discrete search space\u001b[39;00m\n\u001b[1;32m     49\u001b[0m rparams \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_estimators\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_choices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_estimators\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m, param_choices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m, param_choices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubsample\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubsample\u001b[39m\u001b[38;5;124m\"\u001b[39m, param_choices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubsample\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolsample_bytree\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolsample_bytree\u001b[39m\u001b[38;5;124m\"\u001b[39m, param_choices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolsample_bytree\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_child_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_child_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m, param_choices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_child_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m, param_choices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# NEW: regularization terms\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlambda\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlambda\u001b[39m\u001b[38;5;124m\"\u001b[39m, param_choices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlambda\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m\"\u001b[39m, param_choices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m     60\u001b[0m }\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Global index for logging (across reruns)\u001b[39;00m\n\u001b[1;32m     63\u001b[0m global_idx \u001b[38;5;241m=\u001b[39m n_complete \u001b[38;5;241m+\u001b[39m i  \u001b[38;5;66;03m# 0-based index among desired trials\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nf1_analysis/lib/python3.9/site-packages/optuna/trial/_trial.py:408\u001b[0m, in \u001b[0;36mTrial.suggest_categorical\u001b[0;34m(self, name, choices)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Suggest a value for the categorical parameter.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03mThe value is sampled from ``choices``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;124;03m    :ref:`configurations` tutorial describes more details and flexible usages.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# There is no need to call self._check_distribution because\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;66;03m# CategoricalDistribution does not support dynamic value space.\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_suggest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCategoricalDistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchoices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchoices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nf1_analysis/lib/python3.9/site-packages/optuna/trial/_trial.py:643\u001b[0m, in \u001b[0;36mTrial._suggest\u001b[0;34m(self, name, distribution)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;66;03m# `param_value` is validated here (invalid value like `np.nan` raises ValueError).\u001b[39;00m\n\u001b[1;32m    642\u001b[0m param_value_in_internal_repr \u001b[38;5;241m=\u001b[39m distribution\u001b[38;5;241m.\u001b[39mto_internal_repr(param_value)\n\u001b[0;32m--> 643\u001b[0m \u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_trial_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_value_in_internal_repr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistribution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_frozen_trial\u001b[38;5;241m.\u001b[39mdistributions[name] \u001b[38;5;241m=\u001b[39m distribution\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_frozen_trial\u001b[38;5;241m.\u001b[39mparams[name] \u001b[38;5;241m=\u001b[39m param_value\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nf1_analysis/lib/python3.9/site-packages/optuna/storages/_cached_storage.py:162\u001b[0m, in \u001b[0;36m_CachedStorage.set_trial_param\u001b[0;34m(self, trial_id, param_name, param_value_internal, distribution)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mset_trial_param\u001b[39m(\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    157\u001b[0m     trial_id: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m     distribution: distributions\u001b[38;5;241m.\u001b[39mBaseDistribution,\n\u001b[1;32m    161\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_trial_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_value_internal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistribution\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nf1_analysis/lib/python3.9/site-packages/optuna/storages/_rdb/storage.py:586\u001b[0m, in \u001b[0;36mRDBStorage.set_trial_param\u001b[0;34m(self, trial_id, param_name, param_value_internal, distribution)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mset_trial_param\u001b[39m(\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    580\u001b[0m     trial_id: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    583\u001b[0m     distribution: distributions\u001b[38;5;241m.\u001b[39mBaseDistribution,\n\u001b[1;32m    584\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _create_scoped_session(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoped_session, \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m--> 586\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_trial_param_without_commit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m            \u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_value_internal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistribution\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nf1_analysis/lib/python3.9/site-packages/optuna/storages/_rdb/storage.py:608\u001b[0m, in \u001b[0;36mRDBStorage._set_trial_param_without_commit\u001b[0;34m(self, session, trial_id, param_name, param_value_internal, distribution)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_trial_is_updatable(trial_id, trial\u001b[38;5;241m.\u001b[39mstate)\n\u001b[1;32m    601\u001b[0m trial_param \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mTrialParamModel(\n\u001b[1;32m    602\u001b[0m     trial_id\u001b[38;5;241m=\u001b[39mtrial_id,\n\u001b[1;32m    603\u001b[0m     param_name\u001b[38;5;241m=\u001b[39mparam_name,\n\u001b[1;32m    604\u001b[0m     param_value\u001b[38;5;241m=\u001b[39mparam_value_internal,\n\u001b[1;32m    605\u001b[0m     distribution_json\u001b[38;5;241m=\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mdistribution_to_json(distribution),\n\u001b[1;32m    606\u001b[0m )\n\u001b[0;32m--> 608\u001b[0m \u001b[43mtrial_param\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_and_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstudy_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nf1_analysis/lib/python3.9/site-packages/optuna/storages/_rdb/models.py:373\u001b[0m, in \u001b[0;36mTrialParamModel.check_and_add\u001b[0;34m(self, session, study_id)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_and_add\u001b[39m(\u001b[38;5;28mself\u001b[39m, session: orm\u001b[38;5;241m.\u001b[39mSession, study_id: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 373\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_compatibility_with_previous_trial_param_distributions\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudy_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m     session\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nf1_analysis/lib/python3.9/site-packages/optuna/storages/_rdb/models.py:387\u001b[0m, in \u001b[0;36mTrialParamModel._check_compatibility_with_previous_trial_param_distributions\u001b[0;34m(self, session, study_id)\u001b[0m\n\u001b[1;32m    379\u001b[0m previous_record \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    380\u001b[0m     session\u001b[38;5;241m.\u001b[39mquery(TrialParamModel)\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;241m.\u001b[39mjoin(TrialModel)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;241m.\u001b[39mfirst()\n\u001b[1;32m    385\u001b[0m )\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m previous_record \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 387\u001b[0m     \u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_distribution_compatibility\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson_to_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprevious_record\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribution_json\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson_to_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribution_json\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nf1_analysis/lib/python3.9/site-packages/optuna/distributions.py:656\u001b[0m, in \u001b[0;36mcheck_distribution_compatibility\u001b[0;34m(dist_old, dist_new)\u001b[0m\n\u001b[1;32m    654\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dist_old \u001b[38;5;241m!=\u001b[39m dist_new:\n\u001b[0;32m--> 656\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    657\u001b[0m         CategoricalDistribution\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m does not support dynamic value space.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    658\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: CategoricalDistribution does not support dynamic value space."
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score  # CHANGED\n",
    "\n",
    "# Hyperparameter search for XGBoost (with timing logs)\n",
    "overall_start = time.time()\n",
    "\n",
    "# Ensure tuning directory exists (relative to 1.train_models/)\n",
    "os.makedirs(\"tuning\", exist_ok=True)\n",
    "\n",
    "# Create/load persistent Optuna study\n",
    "study = optuna.create_study(\n",
    "    study_name=\"xgb_cv_v2\",  \n",
    "    direction=\"maximize\",\n",
    "    storage=\"sqlite:///tuning/optuna_xgb_v2.sqlite3\",  \n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "\n",
    "# How many trials have already successfully finished?\n",
    "completed_trials = [t for t in study.trials if t.state == TrialState.COMPLETE]\n",
    "n_complete = len(completed_trials)\n",
    "\n",
    "# Initialize best from existing study, if any\n",
    "if n_complete > 0:\n",
    "    best_trial_so_far = study.best_trial\n",
    "    best_acc = float(best_trial_so_far.value)  # now best AUC\n",
    "    best_hp = best_trial_so_far.params.copy()\n",
    "else:\n",
    "    best_acc = -np.inf\n",
    "    best_hp = None\n",
    "\n",
    "# Decide how many *new* trials to run this time\n",
    "n_to_run = max(0, rand_iter - n_complete)\n",
    "\n",
    "logger.info(\n",
    "    f\"{datetime.now().isoformat(timespec='seconds')} \"\n",
    "    f\"[INFO] Loaded Optuna study 'xgb_cv' with \"\n",
    "    f\"{len(study.trials)} total trials ({n_complete} completed). \"\n",
    "    f\"Target total trials = {rand_iter}. \"\n",
    "    f\"Running {n_to_run} new trials in this session.\"\n",
    ")\n",
    "\n",
    "for i in range(n_to_run):\n",
    "    trial = study.ask()\n",
    "\n",
    "    # Draw hyperparameters from your (more regularized) discrete search space\n",
    "    rparams = {\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", param_choices[\"n_estimators\"]),\n",
    "        \"max_depth\": trial.suggest_categorical(\"max_depth\", param_choices[\"max_depth\"]),\n",
    "        \"learning_rate\": trial.suggest_categorical(\"learning_rate\", param_choices[\"learning_rate\"]),\n",
    "        \"subsample\": trial.suggest_categorical(\"subsample\", param_choices[\"subsample\"]),\n",
    "        \"colsample_bytree\": trial.suggest_categorical(\"colsample_bytree\", param_choices[\"colsample_bytree\"]),\n",
    "        \"min_child_weight\": trial.suggest_categorical(\"min_child_weight\", param_choices[\"min_child_weight\"]),\n",
    "        \"gamma\": trial.suggest_categorical(\"gamma\", param_choices[\"gamma\"]),\n",
    "        # NEW: regularization terms\n",
    "        \"lambda\": trial.suggest_categorical(\"lambda\", param_choices[\"lambda\"]),\n",
    "        \"alpha\": trial.suggest_categorical(\"alpha\", param_choices[\"alpha\"]),\n",
    "    }\n",
    "\n",
    "    # Global index for logging (across reruns)\n",
    "    global_idx = n_complete + i  # 0-based index among desired trials\n",
    "\n",
    "    iter_start = time.time()\n",
    "    print(\n",
    "        f\"{datetime.now().isoformat(timespec='seconds')} \"\n",
    "        f\"[INFO] Iteration {global_idx + 1}/{rand_iter}: trying params = {rparams} \"\n",
    "        f\"(Optuna trial {trial.number})\"\n",
    "    )\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "    # Combine fixed XGBoost params with the sampled hyperparameters\n",
    "    comb_params = xgb_params | rparams\n",
    "\n",
    "    # Reset eval data for this hyperparameter setting\n",
    "    eval_data = defaultdict(list)\n",
    "    sum_auc = 0.0     # CHANGED: track AUC for objective\n",
    "    sum_acc = 0.0     # keep accuracy for logging\n",
    "\n",
    "    # Loop through the folds\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X, y), start=1):\n",
    "        fold_start = time.time()\n",
    "\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        # Create a shuffled version of the validation features for the null model\n",
    "        X_val_shuf = X_val.copy()\n",
    "        shuffle_data(X_val_shuf)\n",
    "\n",
    "        # Train XGBoost model on this fold\n",
    "        model = XGBClassifier(**comb_params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate on validation fold\n",
    "        # CHANGED: use probabilities for AUC, predictions for accuracy\n",
    "        y_proba = model.predict_proba(X_val)[:, 1]\n",
    "        preds = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "        sum_auc += roc_auc_score(y_val, y_proba)\n",
    "        sum_acc += accuracy_score(y_val, preds)\n",
    "\n",
    "        # Store predictions for evaluation (real and shuffled)\n",
    "        store_pre_evaluation_data(\n",
    "            X_val, y_val, restdf.iloc[val_index][meta_cols], \"val\"\n",
    "        )\n",
    "        store_pre_evaluation_data(\n",
    "            X_val_shuf, y_val, restdf.iloc[val_index][meta_cols], \"shuffled_val\"\n",
    "        )\n",
    "\n",
    "        fold_time = (time.time() - fold_start) / 60\n",
    "        logger.info(\n",
    "            f\"{datetime.now().isoformat(timespec='seconds')} \"\n",
    "            f\"[INFO]    Fold {fold}/{n_splits} finished in {fold_time:.2f} min\"\n",
    "        )\n",
    "\n",
    "    # Average metrics across folds\n",
    "    mean_auc = sum_auc / n_splits\n",
    "    mean_acc = sum_acc / n_splits\n",
    "\n",
    "    # Keep best performing hyperparameters and their eval data (within this session)\n",
    "    if mean_auc > best_acc:   # CHANGED: use AUC as objective\n",
    "        best_acc = mean_auc\n",
    "        best_hp = rparams\n",
    "        best_eval_data = {k: v.copy() for k, v in eval_data.items()}\n",
    "\n",
    "    # Attach some metadata to the trial (optional but useful)\n",
    "    trial.set_user_attr(\"params\", rparams)\n",
    "    trial.set_user_attr(\"comb_params\", comb_params)\n",
    "    trial.set_user_attr(\"mean_cv_auc\", float(mean_auc))\n",
    "    trial.set_user_attr(\"mean_cv_acc\", float(mean_acc))\n",
    "    trial.set_user_attr(\"n_splits\", n_splits)\n",
    "\n",
    "    # Tell Optuna about this trial's result (AUC)\n",
    "    study.tell(trial, mean_auc)\n",
    "\n",
    "    iter_time = (time.time() - iter_start) / 60\n",
    "    logger.info(\n",
    "        f\"{datetime.now().isoformat(timespec='seconds')} \"\n",
    "        f\"[INFO] Iteration {global_idx + 1} finished in {iter_time:.2f} min \"\n",
    "        f\"(AUC={mean_auc:.4f}, ACC={mean_acc:.4f}, best_AUC={best_acc:.4f})\"\n",
    "    )\n",
    "\n",
    "total_time = (time.time() - overall_start) / 60\n",
    "logger.info(\n",
    "    f\"{datetime.now().isoformat(timespec='seconds')} [INFO] Total search time this session: {total_time:.2f} min\"\n",
    ")\n",
    "\n",
    "# After running any new trials (or if n_to_run == 0), sync to *global* best over the study\n",
    "completed_trials = [t for t in study.trials if t.state == TrialState.COMPLETE]\n",
    "if not completed_trials:\n",
    "    raise RuntimeError(\"No completed Optuna trials in the study. Nothing to select as best.\")\n",
    "\n",
    "best_trial = study.best_trial\n",
    "best_acc = float(best_trial.value)      # still the best AUC\n",
    "best_hp = best_trial.params.copy()\n",
    "\n",
    "logger.info(\n",
    "    f\"{datetime.now().isoformat(timespec='seconds')} \"\n",
    "    f\"[INFO] Best average validation AUC (all completed trials) = {best_acc:.4f}\"\n",
    ")\n",
    "logger.info(f\"Best hyperparameters (global over study) = {best_hp}\")\n",
    "\n",
    "# Set eval_data to the best hyperparameter results for saving later, if available\n",
    "eval_data = defaultdict(list)\n",
    "if best_eval_data is not None:\n",
    "    for k, v in best_eval_data.items():\n",
    "        eval_data[k].extend(v)\n",
    "else:\n",
    "    logger.info(\n",
    "        f\"{datetime.now().isoformat(timespec='seconds')} \"\n",
    "        \"[INFO] No best_eval_data from this session (e.g., no new trials ran). \"\n",
    "        \"eval_data left empty; global best_hp is taken from the Optuna study.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "4D42C7hQua"
   },
   "source": [
    "## Retrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T03:13:23.297509Z",
     "iopub.status.busy": "2024-07-20T03:13:23.297314Z",
     "iopub.status.idle": "2024-07-20T03:13:32.871574Z",
     "shell.execute_reply": "2024-07-20T03:13:32.870797Z"
    },
    "jukit_cell_id": "FNeiZcYJzz"
   },
   "outputs": [],
   "source": [
    "# Retrain XGBoost on all training data using best hyperparameters\n",
    "comb_params = xgb_params | best_hp\n",
    "\n",
    "model = XGBClassifier(**comb_params)\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "RjJUksr4Hk"
   },
   "source": [
    "## Shuffle train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T03:13:32.875142Z",
     "iopub.status.busy": "2024-07-20T03:13:32.874899Z",
     "iopub.status.idle": "2024-07-20T03:13:39.567201Z",
     "shell.execute_reply": "2024-07-20T03:13:39.566773Z"
    },
    "jukit_cell_id": "Hwc1Sal9AZ"
   },
   "outputs": [],
   "source": [
    "X_shuf = X.copy()\n",
    "shuffle_data(X_shuf)\n",
    "\n",
    "X_test_shuf = X_test.copy()\n",
    "shuffle_data(X_test_shuf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "bhXkY9LWcL"
   },
   "source": [
    "# Save models and model data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "IKb986kQIQ"
   },
   "source": [
    "## Store pre-evaluation split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T03:13:39.569719Z",
     "iopub.status.busy": "2024-07-20T03:13:39.569566Z",
     "iopub.status.idle": "2024-07-20T03:13:39.726629Z",
     "shell.execute_reply": "2024-07-20T03:13:39.726190Z"
    },
    "jukit_cell_id": "4uw0FlkRQV"
   },
   "outputs": [],
   "source": [
    "store_pre_evaluation_data(X, y, restdf[meta_cols], \"train\")\n",
    "store_pre_evaluation_data(X_shuf, y, restdf[meta_cols], \"shuffled_train\")\n",
    "\n",
    "store_pre_evaluation_data(X_test, y_test, testdf[meta_cols], \"test\")\n",
    "store_pre_evaluation_data(X_test_shuf, y_test, testdf[meta_cols], \"shuffled_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T03:13:39.729183Z",
     "iopub.status.busy": "2024-07-20T03:13:39.729027Z",
     "iopub.status.idle": "2024-07-20T03:14:13.289064Z",
     "shell.execute_reply": "2024-07-20T03:14:13.288371Z"
    },
    "jukit_cell_id": "ONBKrPrWx0"
   },
   "outputs": [],
   "source": [
    "suffix = \"_qc\" if data_level == \"cleaned\" else \"\"\n",
    "\n",
    "dump(model, f\"{data_path}/trained_nf1_model{suffix}.joblib\")\n",
    "dump(le, f\"{data_path}/trained_nf1_model_label_encoder{suffix}.joblib\")\n",
    "pd.DataFrame(eval_data).to_parquet(\n",
    "    f\"{data_path}/nf1_model_pre_evaluation_results{suffix}.parquet\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "nf1_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
